# Fine Tuning for GPT-base-model
gptのベースモデルに対するファインチューニングを学ぶ

## ファイル構成
* fine_tuning.ipynb - ファインチューニングサンプルコード
* training_data.jsonl - トレーニング用データセット
* validation_data.jsonl - バリデーション用データセット
* training_validation_loss.csv - モデル訓練時の各損失推移
* evaluating_method.md - OpenAIにおけるカスタムモデルのテストapiについて

## Fine Tuningの目的
* LLMのベースモデルに対して、特定のタスクやドメインに特化した比較的小規模なデータセットを追加で学習させるプロセスにより、モデルの振る舞いをカスタマイズし、特定のユースケースにおける性能を向上させることができる。

## Fine Tuningの注意点
* fine tuningは、モデルを特定の方向に<b>特化</b>させるプロセスであり、汎用的な知識を新たに追加するものではない。むしろ、モデルが既に持つ広範な知識を元に、特定のタスクにおける応答の仕方、スタイル、精度を調整するもの。
* 特定の分野の専門知識をゼロから教え込むためには、RAGの方が適している場合がある。

## プロンプトエンジニアリング/RAG/Fine Tuningの選択
  誤ったアプローチを選択すると、期待した成果が得られないばかりか、時間やリソースを無駄にするので注意。<br>例えば、頻繁に更新される事実情報をファインチューニングで教え込もうとするのは非効率的で、RAGの方が適している。<br>逆に、特定の複雑な出力フォーマットを一貫して生成させたい場合は、プロンプトエンジニアリングだけでは限界があり、ファインチューニングが有効な手段となり得る。

## Fine Tuningの利点
1. スタイル、トーン、フォーマットの制御
    * 例えば、カスタマーサポートのチャットボットが常に丁寧で共感的な言葉遣いをし、特定のテンプレートに従って回答を生成するように学習させる。
2. 応答の信頼性向上
    * 多数の正解例でファインチューニングを行うことで、望ましくない応答を生成する可能性を減らし、一貫性を向上させることができる。
3. 複雑な指示への対応
    * プロンプトが非常に長くなったり、複数の条件や制約を含む複雑な指示になったりする場合、モデルがそれらを完全に理解し、常に正しく従うことが難しくなる。ファインチューニングは、これらの複雑な指示をモデルの<b>内部知識</b>として組み込むような効果があり、より短いプロンプトでも複雑な要求に答えられるようにする。これは、実質的に複雑なプロンプトエンジニアリングのロジックをモデルの重みに<b>圧縮</b>するようなものと考えることができ、結果として、推論時のAPI呼び出しが効率化（コスト削減、レイテンシ短縮）される。
4. 多数のエッジケース(稀な状況)への対応
    * 予期しない入力や稀な状況(エッジケース)に対して、それぞれ適切な対応方法を定義し、それらの例でモデルをファインチューニングすることで、信頼性の高いシステムを構築する。
5. プロンプトでは表現しにくい新しいスキルの学習
    * 一部のタスクやスキルは、自然言語の指示だけではモデルに正確に伝えるのが難しい場合がある。例えば、特定の種類の創造的な文章作成、特定のパターンのデータ交換、微妙なニュアンスを伴う判断など。この場合、多数の具体的な入出力例を通じてファインチューニングを行うことで、モデルにその新しいスキルや振る舞いを<b>体感</b>させることができる。

<br>

<b>ファインチューニングは、単にモデルの知識を増やすのではなく、特定のタスクにおける『振る舞い』を洗練させるプロセス</b>

<br>

## 教師ありファインチューニング（Supervised Fine-Tuning: SFT）のプロセス
* 入力（プロンプト）とそれに対応する望ましい出力（理想的なモデルの応答）のペアからなるデータセットを用いてモデルを訓練する

### Step
1. トレーニングデータセットの構築、準備
2. トレーニングデータのアップロード
3. ファインチューニングジョブの作成（モデルの訓練）
4. 結果の評価とファインチューニング済みモデルの利用

##### 注!:反復プロセス
　ファインチューニングは、一度で完璧な結果が得られるとは限らない。多くの場合、最初の試行で期待した性能向上に至らず、データセットの改善（例の追加や修正）、プロンプトの見直し、ハイパーパラメータの調整（OpenAI側でほとんど自動化されている）などを行い、再度ファインチューニングジョブを実行するという反復的なプロセスが必要

<br>

### 1. トレーニングデータセットの構築、準備
* <b>ファインチューニングの成功は、トレーニングデータセットの品質に大きく依存する</b>
* トレーニングデータはJSON Lines形式で提供
* トレーニングデータの構造化(chat model用messages配列)
  * Chatcomplition api向けのモデルをファインチューニングする場合、トレーニングデータの各JSONL行は、Chatcomplition apiの入力と同じmessages配列形式で構成する
  * 一つのトレーニング例のmessages配列内に、複数のassistantメッセージを含めることも可能（例えば、ユーザーとアシスタントが複数回やり取りする会話の例など）

#### 高品質なトレーニングデータを作るための原則
1. 量より質を優先する（特にトレーニング初期）
    * 多数の低品質なデータセットよりも、少数の非常によく練られたデータセットから始めるのが効果的。まずは、質の高い50~100個のデータセットで試し、効果を見極める。
2. 現実性を追及する
    * トレーニングデータは、実際のアプリケーションでモデルが遭遇すると想定されるプロンプトと、それに対する理想的な出力を可能な限り忠実に反映させる。現実離れした例や実際のユースケースと乖離した例では、モデルは実用的な能力を学習できない。
3. 明確かつ具体的
    * ユーザーからの質問（プロンプト）は具体的で、アシスタントの応答（正解ラベル）は明確かつ曖昧さがないようにする。モデルが何を学習すべきかをはっきりと示すことが重要。
4. 多様なデータソースの活用
    * 過去のインタラクションログ、専門家が作成したデータ、実際の業務で収集されたデータなど、多様なソースからデータを収集する。これにより、モデルはより幅広い状況に対応できるようになる。
5. 一貫性を保つ
    * 複数の人間がデータを作成する場合、応答のスタイル、トーン、情報の正確性などについて一貫性を保つことが重要。データ作成者間での指示の解釈やアウトプットの質にばらつきがあると、モデルの学習効率が低下し、性能が頭打ちになる。
6. 応答に必要な情報を網羅する
    * アシスタントの応答を生成するために必要なすべての情報が、プロンプト（ユーザーメッセージやシステムメッセージ）に含まれていることを確認する。情報が不足していると、モデルは事実に基づかない情報（ハルシネーション）を生成してしまう可能性がある。
7. バランスと多様性を考慮する
    * データセット内の応答の種類やトピックのバランスに注意する。例えば、特定の種類の応答がデータセットの大部分を占めていると、モデルはその応答を過剰に生成する傾向を持つ可能性がある。実際の運用で期待される応答の分布を考慮し、多様な例を含めることが望ましい。
8. 課題を特定し、対象を絞った例を追加する
    * ファインチューニング後もモデルが特定の部分で期待通りに動作しない場合、その問題点を具体的に示し、正しい振る舞いを教えるための例を追加する。
9. 既存のデータを精査する
    * データセットに文法的な誤り、論理的な矛盾、不適切なスタイルなどが含まれていないかを確認する。モデルはこれらの欠点も学習してしまう可能性がある。

<br>
<b>ファインチューニング用データセットは、モデルに対する『手本になる仕様書』みたいなもの。モデルは、これらの手本からどのような入力に対して、どのように応答すべきかを学ぶ</b>

<br><br>

#### 必要データ量について
まずは50個程度で始めて見て、
* 性能が向上した場合：
  * さらに例を追加することで、さらなる性能向上が見込めるか検討する。
* 全く効果が見られない：
  * 例の数を増やす前に、タスク定義そのものや、各例のプロンプトの質、応答の質を見直す。この段階で効果がない場合、データ量を増やすだけでは問題は解決しない。

#### ファインチューニング用データの収集・生成戦略
1. 手作業による作成
    * 初期フェーズの高品質な例を作成する場合や、非常に微妙なスタイルの調整を行いたい場合
2. 既存データの活用
    * 過去の成功事例や望ましい対応パターンが記録として残っている場合
3. LLMを利用したデータ生成
    * データセットの量を増やしたい場合や、多様なバリエーションの例を効率的に作成したい場合。ただし、常に人間の監視下で行うべき。

##### 望ましい応答パターンの特定と作成
* 既存のモデル（ベースモデル、またはファインチューニング途中のモデル）の出力を分析し、どこで期待通りに動作しないか、どのような応答が不適切かを到底する。そして、それらのシナリオに対して理想的な応答を定義し、新たなトレーニング例として追加する。これは、モデルの弱点を補強するための的を絞ったアプローチ。

##### データ拡張
* 既存の高品質なトレーニング例に対して、意味を保ちつつ表現をわずかに変更したり（例：言い換え、類義語の使用）、ノイズを加えたりすることで、データのバリエーションを増やす手法。ただし、元の例の品質を損なわないように注意が必要

<br>

### 2. トレーニングデータのアップロード
JSON Lines形式のトレーニングデータセットをOpenAIプラットフォームにアップロード
* 方法：
    1. OpenAI ダッシュボード(UI)からアップロード
    2. OpenAI apiによるアップロード(pythonなど)

<br>

### 3.ファインチューニングジョブの作成（モデルの訓練）
#### ジョブ作成時の必須パラメータ
1. アップロードしたファイルのidプロパティ
2. モデル（ベースモデル / ファインチューニングしたカスタムモデル）

#### ジョブ作成時のオプションパラメータ（一部）
* validation file（検証ファイルのID）
  * トレーニングデータとは別に用意した検証用データセットのファイルIDを指定。これを指定すると、訓練中にモデルが未知のデータに対してどの程度汎化できているかのメトリクス（検証損失など）が計算され、過学習の検出などに役立つ。
* ハイパーパラメータ
  * batch_size, learning_rate_multiplier, n_epochs
  * ※上記3つのハイパーパラメータはデフォルトでautoのため、自動設定される。
* suffix
  * ファインチューニング後に生成されるカスタムモデルの名前の設定

#### トレーニング進捗のモニタリング
* 進捗確認方法：
    1. OpenAI ダッシュボードでの確認
    2. api経由での確認

* 主要な訓練メトリクス：
  * <b>training_loss (訓練損失)</b>
    * トレーニングデータセットに対するモデルの予測誤差を示す。この値は訓練が進むにつれて減少していくのが理想的。損失が十分に下がらない場合、モデルがデータをうまく学習できていない可能性がある。
  * <b>validation_loss (検証損失)</b>
    * 検証データセットに対するモデルの予測誤差。この値は、モデルが未知のデータに対してどの程度汎化できているかを示す。
  * <b>training_token_accuracy (訓練トークン精度)</b>
    * トレーニングデータセットにおいて、モデルが次のトークンを正しく予測できた割合を示す。
  * <b>validation_token_accuracy (検証トークン精度)</b>
    * 検証データセットにおける次のトークンの予測精度。
* メトリクスの解釈と重要性：
  * <b>アンダーフィッティング (学習不足)</b>
    * 訓練損失も検証損失も高いままで、十分に減少しない場合、モデルはデータから十分にパターンを学習できていない。データ量の不足、データ品質の問題、あるいはモデルの表現力不足などが原因として考えられる。
  * <b>オーバーフィッティング (過学習)</b>
    * 訓練損失は順調に減少する一方で、検証損失がある時点から横ばいになるか、逆に増加し始める場合、モデルはトレーニングデータに過剰に適合してしまい、未知のデータに対する汎化性能を失っている。これは、モデルが訓練データのノイズまで学習してしまっている状態。
  * <b>良好な学習</b>
    * 訓練損失と検証損失がともに順調に減少し、低い値で安定する場合、モデルは適切に学習し、汎化性能も獲得している。
* 補足：
  * ファインチューニングの実行中、OpenAIは定期的にモデルの状態のスナップショット(チェックポイント)を作成する。訓練終了後、これらのチェックポイントから最も性能が良いもの(例：検証損失が最小のもの)を選択して、最終的なファインチューニング済みモデルとして利用することができる。

<br>

### 4. 結果の評価とファインチューニング済みモデルの利用
期待通りの改善が得られたかの確認ステップ

#### 方法：
##### 1. OpenAI Playgroundでのテスト：
* 実際のユースケースを想定した様々なプロンプトを入力し、モデルの応答を観察する。
  * 期待するスタイルやトーンで応答しているか？
  * 指示に従っているか？
  * 情報の正確性は向上したか？
  * 特定のエッジケースに対して適切に振舞うか？

##### 2. テストデータによる定量的評価：
* テストデータには、モデルがこれまで見たことのない新しい入出力例を含める。
* このデータセットに対して、ファインチューニング済みモデルとベースモデルの応答を生成させ、その結果を比較する。
* タスクの性質に応じて、適切な評価指標を用いる。
  * <b>分類タスク</b>：正解率(Accuracy), 適合率(Precision), 再現率(Recall), F1スコアなど
  * <b>情報抽出タスク</b>：抽出されたエンティティや情報の正確性、F1スコアなど
  * <b>テキスト生成タスク</b>：BLEU、GOUGEといった自動評価指標の利用
  * <b>特定のフォーマット要求</b>：出力が期待するJSONスキーマに一致する割合など

##### 3. 定性的評価（人間による評価）：
自動評価指標だけでは捉えきれない、応答の自然さ、流暢さ、創造性、ニュアンスの適切さなどを人間により評価
* 複数の評価者に、モデルの応答を特定の基準（例：有用性、正確性、好ましさ）に基づいて評価してもらう。
* A/Bテストのような形式で、ベースモデルの応答とファインチューニング済みモデルの応答を比較評価する。

##### 4. 反復的な改善プロセス：
評価の結果、ファインチューニング済みモデルの性能が期待に達していない場合、原因を分析し、改善策を講じる。
* <b>データセットの見直し</b>：
  * トレーニングデータの質や量に問題はなかったか？
  * モデルが苦手とする特定のパターンに対応する例が不足していなかったか？
  * データのバランスは適切だったか？
* <b>プロンプトの改善</b>：
  * ファインチューニングデータ内のプロンプト（システムメッセージやユーザーメッセージ）が最適か
* <b>ハイパーパラメータの調整(APIで制御可能な場合)</b>：
  * モデルが訓練データに十分に追随していない（学習不足）と感じられる場合、エポック数を増やすことを検討する。
  * モデルの応答の多様性が期待より低い（過学習の兆候）場合、エポックするを減らすことを検討。
  * モデルの学習が収束していないように見える場合、学習率乗数を上げることを検討する。

ファインチューニングと評価のプロセスを経て、期待通りの性能を持つカスタムモデルが完成したら、そのモデルを実際のアプリケーションに統合し、利用を開始する。

<hr>
ファインチューニングのサンプルコードは、fine_tuning_sample.ipynbを参照
<br>

##### Fine Tuning Documentations
* openai docs: https://platform.openai.com/docs/guides/fine-tuning
* openai SFT docs: https://platform.openai.com/docs/guides/supervised-fine-tuning
* openai api docs: https://platform.openai.com/docs/api-reference/fine-tuning

